{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048416c-39f1-4b88-b64e-a13ae667aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2 - classification\n",
    "# 1. feature engineering\n",
    "# 2. variable selection\n",
    "# 3. training and validation\n",
    "# 4. testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c04d5d-aec4-46ae-b67e-1ceda35d08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/data/data_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb600dc1-ae4e-4806-839f-ea92355a0bea",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c6e57-3654-498f-b084-b4f57e7e4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature - BILL_AMT_TOTAL\n",
    "# total bill amount over last 6 mo\n",
    "df['BILL_AMT_TOTAL'] = df[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].sum(axis=1)\n",
    "\n",
    "# check changes\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf0ddd-9c39-4db1-a2ca-b1e411f9f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature - PAY_AMT_TOTAL\n",
    "# total payment amount over last 6 mo\n",
    "df['PAY_AMT_TOTAL'] = df[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].sum(axis=1)\n",
    "\n",
    "# check changes\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f7c8c-abbc-452d-a907-b2873d22a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature - OUTS_AMT_TOTAL\n",
    "# outstanding bill amount over last 6 mo\n",
    "df['OUTS_AMT_TOTAL'] = df[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].sum(axis=1) \\\n",
    "                       - df[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].sum(axis=1)\n",
    "# check changes\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c8f00-313f-4a62-a718-fb9bf3440b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature - PAST_DEFAULTS\n",
    "# number of defaulted payments (PAY_AMTn = 0) over last 6 mo\n",
    "df['PAST_DEFAULTS'] = df[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].apply(lambda x: (x == 0).sum(), axis=1)\n",
    "\n",
    "# check changes\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dbcf4-9399-41b8-aa42-d40cb6b63726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature - EXCEED_LIMIT_BAL\n",
    "# number of times exceeded limit balance over last 6 mo\n",
    "# df[df['BILL_AMT1']>df['LIMIT_BAL']]\n",
    "df['EXCEED_LIMIT_BAL'] = df[['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']] \\\n",
    "                        .apply(lambda col: sum([val > list(col)[0] for idx, val in enumerate(list(col))]), axis=1)\n",
    "# check changes\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe2b82-672c-4b79-aa71-d35c309aefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types - SEX, EDUCATION, MARRIAGE\n",
    "df2 = df.copy()\n",
    "dtype= {'SEX'       : 'category', \n",
    "        'EDUCATION' : 'category',\n",
    "        'MARRIAGE'  : 'category'}\n",
    "\n",
    "df2 = df2.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbe4af-0817-44ea-ba5c-c897dd6b6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "df3 = pd.get_dummies(df2)\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab9150-016c-4cbd-a65e-96be6d4d4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf2132-4893-41da-b19b-8855b7affec4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa050c-9b72-4797-b449-ff43a9034be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "feat = ['LIMIT_BAL', 'AGE', \n",
    "       'BILL_AMT_TOTAL', 'PAY_AMT_TOTAL', 'OUTS_AMT_TOTAL', 'PAST_DEFAULTS', 'EXCEED_LIMIT_BAL',\n",
    "       'SEX_1', 'SEX_2',\n",
    "       'EDUCATION_1', 'EDUCATION_2', 'EDUCATION_3', 'EDUCATION_4',\n",
    "       'MARRIAGE_0', 'MARRIAGE_1', 'MARRIAGE_2', 'MARRIAGE_3']\n",
    "\n",
    "# train test split\n",
    "X = df3[feat]\n",
    "y = df3['RESPONSE']\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d92df-a4ce-4d26-b598-f4790308163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling\n",
    "# get numeric columns\n",
    "num_col = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# scaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train[num_col] = scaler.fit_transform(X_train[num_col])\n",
    "X_test[num_col] = scaler.fit_transform(X_test[num_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020db05-82cc-4ac1-8d66-dd9ef938f5ef",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e17d49-79fa-47d1-8dff-aa3a1ba1d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning model - logistic regression\n",
    "# instantiate model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "hyperparameters = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                   'C' : np.logspace(-4, 4, 20),\n",
    "                   'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "                   'max_iter' : [100, 1000,2500, 5000]\n",
    "                  }\n",
    "\n",
    "# define scoring metrics\n",
    "metrics = 'accuracy'\n",
    "\n",
    "# instantiate randomizedsearch\n",
    "lr1 = RandomizedSearchCV(model, hyperparameters, scoring=metrics, cv=5, refit='accuracy', verbose = 1, n_jobs = -1)\n",
    "lr1.fit(X_train, y_train)\n",
    "\n",
    "# get best model\n",
    "best_lr1 = lr1.best_estimator_\n",
    "\n",
    "# generate predictions\n",
    "y_pred_lr1 = best_lr1.predict(X_train)\n",
    "y_pred_proba_lr1 = best_lr1.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_lr1))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_train, y_pred_proba_lr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23875549-030c-49ca-9c70-63bbee8956ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - logistic regression\n",
    "# ranking features with RFE\n",
    "selector = RFE(best_lr1, n_features_to_select = 1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "# print rankings\n",
    "lr_feature_ranks = []\n",
    "for i in selector.ranking_:\n",
    "    lr_feature_ranks.append(feat[i-1])\n",
    "lr_feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e259c-2679-4eaf-96b5-48555ef61491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning model - random forest\n",
    "# instantiate model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "hyperparameters = {'n_estimators'     : [350, 400, 450, 500],\n",
    "                   'max_features'     : ['auto', 'sqrt'],\n",
    "                   'max_depth'        : [5, 10, 15, 25, 30],\n",
    "                   'min_samples_split': [2, 5, 10, 15, 100],\n",
    "                   'min_samples_leaf' : [1, 2, 5, 10, 15]\n",
    "                  }\n",
    "\n",
    "# define scoring metrics\n",
    "metrics = 'accuracy'\n",
    "\n",
    "# instantiate randomizedsearch\n",
    "rf1 = RandomizedSearchCV(model, hyperparameters, scoring=metrics, cv=5, refit='accuracy', verbose = 1, n_jobs = -1)\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "# get best model\n",
    "best_rf1 = rf1.best_estimator_\n",
    "\n",
    "# generate predictions\n",
    "y_pred_rf1 = best_rf1.predict(X_train)\n",
    "y_pred_proba_rf1 = best_rf1.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_rf1))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_train, y_pred_proba_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4c96f-6dbf-4c9b-ab76-d0e1b94a829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - random forest\n",
    "importances = best_rf1.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "rf_feature_ranks = [feat[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), rf_feature_ranks)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f3188-dcac-44ab-a4e9-3fd3cf59287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning model - xgboost\n",
    "# instantiate the classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# create a dictionary of hyperparameters to tune \n",
    "hyperparameters = {'n_estimators' : [200, 300, 400, 500],\n",
    "                   'max_depth'    : [2, 4, 5, 10, 15, 25],\n",
    "                   'learning_rate': [0.01, 0.05, 0.1, 1]\n",
    "                  }\n",
    "\n",
    "# define scoring metrics\n",
    "metrics = 'accuracy'\n",
    "\n",
    "# instantiate randomizedsearch\n",
    "xgb1 = RandomizedSearchCV(model, hyperparameters, scoring=metrics, cv=5, refit='accuracy', verbose = 1, n_jobs = -1)\n",
    "xgb1.fit(X_train, y_train)\n",
    "\n",
    "# get best model\n",
    "best_xgb1 = xgb1.best_estimator_\n",
    "\n",
    "# generate predictions\n",
    "y_pred_xgb1 = best_xgb1.predict(X_train)\n",
    "y_pred_proba_xgb1 = best_xgb1.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_xgb1))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_train, y_pred_proba_xgb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fdae2-c295-4f16-bc19-f36f12f0b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - xgboost\n",
    "# feature importance plot\n",
    "feature_important = xgb1.best_estimator_.get_booster().get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "xgb_feature_ranks = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).nlargest(len(feat), columns='score').sort_values(by=\"score\", ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(xgb_feature_ranks.index, xgb_feature_ranks['score'], color='b', align='center')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a84689-b39c-4ba8-bc09-15afa4e12f4e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0561894-2046-446f-8f10-222b3656cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - logistic regression\n",
    "lr_X, y = SMOTE().fit_resample(X[lr_feature_ranks[:10]],y)\n",
    "lr_X_train, lr_X_test, lr_y_train, lr_y_test = train_test_split(lr_X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa74dd-f33f-4ab6-a37e-752c33728501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - random forest\n",
    "rf_X, y = SMOTE().fit_resample(X[rf_feature_ranks[::-1][:10]],y)\n",
    "rf_X_train, rf_X_test, rf_y_train, rf_y_test = train_test_split(rf_X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207833f-08d8-4f1e-99e7-e7b154157b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - xgboost\n",
    "xgb_X, y = SMOTE().fit_resample(X[xgb_feature_ranks.index[::-1][:7]],y)\n",
    "xgb_X_train, xgb_X_test, xgb_y_train, xgb_y_test = train_test_split(xgb_X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7c10b-d08a-4822-8da6-b0adfa72fd96",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730b227-93de-4985-8060-dafeeae0c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tuning - retrain logistic regression model\n",
    "# supervised learning model - logistic regression\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "hyperparameters = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                   'C' : np.logspace(-4, 4, 20),\n",
    "                   'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "                   'max_iter' : [100, 1000,2500, 5000]\n",
    "                  }\n",
    "\n",
    "# define scoring metrics\n",
    "metrics = 'accuracy'\n",
    "\n",
    "# instantiate randomizedsearch\n",
    "lr2 = RandomizedSearchCV(model, hyperparameters, scoring=metrics, cv=5, refit='accuracy', verbose = 1, n_jobs = -1)\n",
    "lr2.fit(lr_X_train, lr_y_train)\n",
    "\n",
    "# get best model\n",
    "best_lr2 = lr2.best_estimator_\n",
    "\n",
    "# generate predictions\n",
    "y_pred_lr2 = best_lr2.predict(lr_X_train)\n",
    "y_pred_proba_lr2 = best_lr2.predict_proba(lr_X_train)[:, 1]\n",
    "\n",
    "# metrics\n",
    "print(\"Linear Regression Classifier Metrics with Hyperparameter Tuning:\")\n",
    "print(\"Best Parameters:\", lr2.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(lr_y_train, y_pred_lr2))\n",
    "print(\"Precision:\", precision_score(lr_y_train, y_pred_lr2))\n",
    "print(\"Recall:\", recall_score(lr_y_train, y_pred_lr2))\n",
    "print(\"F1:\", f1_score(lr_y_train, y_pred_lr2))\n",
    "print(\"ROC AUC:\", roc_auc_score(lr_y_train, y_pred_proba_lr2))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(lr_y_train, y_pred_lr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786966b-07a8-4459-96dc-175055d06d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tuning - retrain random forest model\n",
    "# supervised learning model - random forest\n",
    "# instantiate model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "hyperparameters = {'n_estimators'     : [350, 400, 450, 500],\n",
    "                   'max_features'     : ['auto', 'sqrt'],\n",
    "                   'max_depth'        : [5, 10, 15, 25, 30],\n",
    "                   'min_samples_split': [2, 5, 10, 15, 100],\n",
    "                   'min_samples_leaf' : [1, 2, 5, 10, 15]\n",
    "                  }\n",
    "\n",
    "# define scoring metrics\n",
    "metrics = 'accuracy'\n",
    "\n",
    "# instantiate randomizedsearch\n",
    "rf2 = RandomizedSearchCV(model, hyperparameters, scoring=metrics, cv=5, refit='accuracy', verbose = 1, n_jobs = -1)\n",
    "rf2.fit(rf_X_train, rf_y_train)\n",
    "\n",
    "# get best model\n",
    "best_rf2 = rf2.best_estimator_\n",
    "\n",
    "# generate predictions\n",
    "y_pred_rf2 = best_rf2.predict(rf_X_train)\n",
    "y_pred_proba_rf2 = best_rf2.predict_proba(rf_X_train)[:, 1]\n",
    "\n",
    "# metrics\n",
    "print(\"Random Forest Classifier Metrics with Hyperparameter Tuning:\")\n",
    "print(\"Best Parameters:\", rf2.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(rf_y_train, y_pred_rf2))\n",
    "print(\"Precision:\", precision_score(rf_y_train, y_pred_rf2))\n",
    "print(\"Recall:\", recall_score(rf_y_train, y_pred_rf2))\n",
    "print(\"F1:\", f1_score(rf_y_train, y_pred_rf2))\n",
    "print(\"ROC AUC:\", roc_auc_score(rf_y_train, y_pred_proba_rf2))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(rf_y_train, y_pred_rf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab1623-0942-46d9-beae-7bc3749b7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tuning - retrain xgboost model\n",
    "# supervised learning model - xgboost\n",
    "# instantiate the classifier\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# create a dictionary of hyperparameters to tune \n",
    "hyperparameters = {'n_estimators' : [200, 300, 400, 500],\n",
    "                   'max_depth'    : [2, 4, 5, 10, 15, 25],\n",
    "                   'learning_rate': [0.01, 0.05, 0.1, 1]\n",
    "                  }\n",
    "\n",
    "# define scoring metrics\n",
    "metrics = 'accuracy'\n",
    "\n",
    "# instantiate randomizedsearch\n",
    "xgb2 = RandomizedSearchCV(model, hyperparameters, scoring=metrics, cv=5, refit='accuracy', verbose = 1, n_jobs = -1)\n",
    "xgb2.fit(xgb_X_train, xgb_y_train)\n",
    "\n",
    "# get best model\n",
    "best_xgb2 = xgb2.best_estimator_\n",
    "\n",
    "# generate predictions\n",
    "y_pred_xgb2 = best_xgb2.predict(xgb_X_train)\n",
    "y_pred_proba_xgb2 = best_xgb2.predict_proba(xgb_X_train)[:, 1]\n",
    "\n",
    "# metrics\n",
    "print(\"XGBoost Classifier Metrics with Hyperparameter Tuning:\")\n",
    "print(\"Best Parameters:\", xgb2.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(xgb_y_train, y_pred_xgb2))\n",
    "print(\"Precision:\", precision_score(xgb_y_train, y_pred_xgb2))\n",
    "print(\"Recall:\", recall_score(xgb_y_train, y_pred_xgb2))\n",
    "print(\"F1:\", f1_score(xgb_y_train, y_pred_xgb2))\n",
    "print(\"ROC AUC:\", roc_auc_score(xgb_y_train, y_pred_proba_xgb2))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(xgb_y_train, y_pred_xgb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c670928-4a17-4c98-968f-ae243e332609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score comparison\n",
    "scores_dict = {\"Accuracy\" : [accuracy_score(lr_y_train, y_pred_lr2),accuracy_score(rf_y_train, y_pred_rf2),accuracy_score(xgb_y_train, y_pred_xgb2)], \n",
    "               \"Precision\": [precision_score(lr_y_train, y_pred_lr2),precision_score(rf_y_train, y_pred_rf2),precision_score(xgb_y_train, y_pred_xgb2)], \n",
    "               \"Recall\"   : [recall_score(lr_y_train, y_pred_lr2),recall_score(rf_y_train, y_pred_rf2),recall_score(xgb_y_train, y_pred_xgb2)], \n",
    "               \"F1\"       : [f1_score(lr_y_train, y_pred_lr2),f1_score(rf_y_train, y_pred_rf2),f1_score(xgb_y_train, y_pred_xgb2)], \n",
    "               \"ROC AUC\"  : [roc_auc_score(lr_y_train, y_pred_proba_lr2),roc_auc_score(rf_y_train, y_pred_proba_rf2),roc_auc_score(xgb_y_train, y_pred_proba_xgb2)]\n",
    "              }\n",
    "\n",
    "scores_df = pd.DataFrame(data = scores_dict, \n",
    "                         index = [\"linear regression\", \"random forest\", \"xgboost\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73d399-7d26-4582-8076-837d50668d3f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231ad0f-d294-4a9d-b6b1-e98c79009f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit best model with best hyperparameters\n",
    "final_classifier = xgb2.best_estimator_.fit(xgb_X_train, xgb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab314d6e-271f-43ff-a8b3-db0d8ec13711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred_proba = final_classifier.predict_proba(xgb_X_test)[:, 1]\n",
    "y_pred = final_classifier.predict(xgb_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da069920-e3f6-4580-8f0c-bbc2365ac57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "print(\"Final Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(xgb_y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(xgb_y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(xgb_y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(xgb_y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(xgb_y_test, y_pred_proba))\n",
    "target_names = ['Predicted would not leave', 'Predicted would leave']\n",
    "print(\"Classification Report:\\n\",classification_report(xgb_y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91099b89-2e3e-4fc1-b146-9a973b32c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final classifier metrics - confusion matrix\n",
    "cm = confusion_matrix(y_pred, xgb_y_test)\n",
    "cmd = ConfusionMatrixDisplay.from_predictions(xgb_y_test, y_pred, normalize=\"true\", values_format=\".0%\")\n",
    "\n",
    "print(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081f213-3112-4b0c-9475-7e1249ca23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positive rate and true positive rate\n",
    "fpr, tpr, thresholds = roc_curve(xgb_y_test, y_pred_proba)\n",
    "\n",
    "# plot roc curve\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754b63b-f038-436f-9c4d-f77d1dd03b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from eli5 import show_weights\n",
    "vec = DictVectorizer()\n",
    "show_weights(final_classifier, vec=vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8aef6-9d3d-4665-84d2-b04be51d87e1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154d61a4-d7de-48f9-8432-d7a895b02f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate probabilities for original dataset (non-smoted)\n",
    "y_pred_proba_fin = final_classifier.predict_proba(df2[xgb_X_test.columns])[:, 1]\n",
    "y_pred_fin = final_classifier.predict(df2[xgb_X_test.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd26cce-1192-4635-aaab-f58933d59f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df2.copy()\n",
    "df4['DEFAULT_PROBA'] = y_pred_proba_fin\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c8df5-f06d-497f-9034-9b75cbff4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_top_10 = df4.nlargest(10, 'DEFAULT_PROBA')\n",
    "churn_top_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cd7a8-553e-4a73-bcf6-d1e1ba47c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top losses\n",
    "churn_top_10 = churn_top_10[['ID', 'BILL_AMT_TOTAL', 'DEFAULT_PROBA']]\n",
    "churn_top_10['EXPECTED_LOSS'] = churn_top_10['BILL_AMT_TOTAL'] * churn_top_10['DEFAULT_PROBA']\n",
    "churn_top_10.sort_values(by='EXPECTED_LOSS', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
